\section{Image Data Analysis}
\subsection{Introduction}
\noindent
After exploring behavior data, we proceed to image data analysis.  First we need to apply
 convolution to connect behavior stimuli and neural activity. Then we can run general linear
  regression to find activated voxels across time course. Using hypothesis testing, we can 
  actually locate and visualize the activated voxels. After finishing basic steps, we try to 
  apply noise modeling and PCA to compare the MRSS so that we can finally decide our design matrix.

\subsection{Methods}
Here are some of the methods (this needs to be updated soon as well.)

\subsubsection {Convolution}
Our experiment is event-oriented. The subject is shown with the different conditions 
such as gain and loss amounts over random time. After being provided with the conditions,
 the blood flow responses starts to fluctuate. To predict the fMRI signal to an event, we
  need to predict the hemodynamic responses to neural activity. A predictor neural time 
  course is typically obtained by convolution of a condition of the experiment with a sta
  ndard hemodynamic response function. With this predictor, we build our design matrix fo
  r our general linear model on each voxel of a subject's brain. To produce such predicto
  r, we practiced two different approaches.
\begin{itemize}
\item  Convolving with canonical HRF \\
A typical BOLD response to a single, impulsive stimulation resembles a linear combination 
of two Gamma function. This would model a signal is instantly at its peak level at the ons
et of a given condition and instantly undershoot back to around baseline with the offset o
f a condition. We can use this hemodynamic response function as a canonical one. Generally
, the canonical HRF should be a good fit if we believe the subjects to be normal in many c
ortical regions. Using this canonical HRF will help us to find how much the canonical HRF h
as to be scaled enough to account for the signal. However, we want to be more in detail as 
long as 
\begin{enumerate}
  \item The onsets of the HRF can happen in the middle of volumes due to the conditions giv
en at different times. 
  \item The amplitudes vary according to the parametric gain and loss condit
ions. Thus, the true shape of HRF for each subject should vary.
\end{enumerate}

\item  Convolving at finer time resolution \\
Therefore, we would make a neural and hemodynamic regressor at a finer time resolution than
 the TRs, and later sample this regressor at the TR onset times. This refers that stimulus
  onsets do not have to be synchronized with scan TRs.

\begin{itemize} 
\item Result \\
To analyze the difference between two approaches, we compare the MRSS from two linear 
regressions on image data of three subjects (1,2,3) using convolution predictors from 
two different approaches. In the below table, we see the MRSS from linear regression usi
ng the latter approach has slightly lower residuals compared to the former method. This 
makes sense because, using the latter method, we are able to more elaborately preprocess 
the data.
\end{itemize}
\end{itemize}


\subsubsection {GLM}
The first matrix we get from convolution has five columns, which correspond to a column of one
s and 4 cond.txt files in our dataset, respectively. After we get the convolution matrix, we u
se it as our design matrix to run the generalized linear regression on the image data. The dim
ension of our data is (64, 64, 34, 240), so, first we reshape our data into 2 dimensional arra
y, which has the shape of (64*64*34, 240); the first dimension corresponds to 3-dimensional v
oxel indices and the second dimension corresponds to the time slice. Then we pass our design m
atrix into the glm function to calculate the related beta hats. Thus, there are in total 13962
4 beta hats that we get from the regression correspond to the first three dimensions of our im
age data. For example, the first beta hat contains the information about the voxel (0,0,0). Th
en we turn the beta hats back into 4-dimensional shape and run the diagnostic functions on the
 4-d beta hats. Based on the predictors, we can calculate the fitted values and then the resid
 uals. We use the MRSS of the first three dimensions as a measurement of our regression; in gen
 eral, a smaller MRSS indicates a better performance of the regression model. 

\subsubsection {Smoothing}
After we tried with the normal convolution matrix, we also generated high resolution convolution 
matrix and used it for linear regression. It turned out that the MRSS is just reduced by a little
 bit. Then we write a smoothing function to implement the multidimensional Gaussian filter on our
  data. We repeat the same procedures as what we have done in normal convolution on the smoothed 
  data and the MRSS are reduced sharply. Therefore, we concluded that the smoothing method is a 
  good pre-processing when we do the linear regression. 

